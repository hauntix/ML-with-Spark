{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing MLLIB\n",
    "_Movie recommendations using Spark's machine learning library_\n",
    "\n",
    "## MLLIB Capabilities\n",
    "- Feature extraction\n",
    "    - Term Frequency / Inverse Document Frequency useful for search\n",
    "- Basic Statistics\n",
    "    - Chi-squared test, Pearson or Spearman correlation, min, max, mean, variance\n",
    "- Linear regression, logistic regression\n",
    "- Support Vector Machines\n",
    "- Na√Øve Bayes classifier\n",
    "- Decision tress\n",
    "- K-Means clustering\n",
    "- Principal component analysis, singular value decomposition\n",
    "- Reccomendations using Alternating Least Squares\n",
    "\n",
    "## Special MLLIB Data Types\n",
    "- Vector (dense or sparse)\n",
    "- LabeledPoint\n",
    "- Rating\n",
    "\n",
    "### For more depth\n",
    "_Advanced Analytics with Spark from O'Reilly_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie reccomendations example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark import SparkContext\n",
    "from pyspark.mllib.recommendation import ALS, Rating\n",
    "\n",
    "def loadMovieNames():\n",
    "    movieNames = {}\n",
    "    with open(\"../data/u.ITEM\", encoding='ascii', errors=\"ignore\") as f:\n",
    "        for line in f:\n",
    "            fields = line.split('|')\n",
    "            movieNames[int(fields[0])] = fields[1]\n",
    "    return movieNames\n",
    "\n",
    "sc = SparkContext(\"local[*]\", \"MovieRecommendationsALS\")\n",
    "sc.setCheckpointDir('checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading movie names...\n",
      "\n",
      "Training recommendation model...\n",
      "\n",
      "Ratings for user ID 0:\n",
      "\tStar Wars (1977): 5.0\n",
      "\tEmpire Strikes Back, The (1980): 5.0\n",
      "\tGone with the Wind (1939): 1.0\n",
      "\n",
      "\n",
      "Top 10 recommendations:\n",
      "\tSchizopolis (1996) score 8.263297649808099\n",
      "\tDie xue shuang xiong (Killer, The) (1989) score 7.751917667658414\n",
      "\tGo Fish (1994) score 7.581591837883766\n",
      "\tMighty Morphin Power Rangers: The Movie (1995) score 7.567052272721566\n",
      "\tHarlem (1993) score 7.5323154493001345\n",
      "\tHard Rain (1998) score 6.76689679471007\n",
      "\tShooting Fish (1997) score 6.612484231447633\n",
      "\tMy Man Godfrey (1936) score 6.531903894422301\n",
      "\tShall We Dance? (1937) score 6.364868078374405\n",
      "\tInspector General, The (1949) score 6.339408173163396\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLoading movie names...\")\n",
    "nameDict = loadMovieNames()\n",
    "\n",
    "data = sc.textFile(\"../data/u.data\")\n",
    "\n",
    "ratings = data.map(lambda l: l.split()).map(lambda l: Rating(int(l[0]), int(l[1]), float(l[2]))).cache()\n",
    "\n",
    "# Build the recommendation model using Alternating Least Squares\n",
    "print(\"\\nTraining recommendation model...\")\n",
    "rank = 10\n",
    "# Lowered numIterations to ensure it works on lower-end systems\n",
    "numIterations = 20\n",
    "model = ALS.train(ratings, rank, numIterations)\n",
    "\n",
    "userID = 0 # int(sys.argv[1])\n",
    "\n",
    "print(\"\\nRatings for user ID \" + str(userID) + \":\")\n",
    "userRatings = ratings.filter(lambda l: l[0] == userID)\n",
    "for rating in userRatings.collect():\n",
    "    print (\"\\t\" + nameDict[int(rating[1])] + \": \" + str(rating[2]))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"\\nTop 10 recommendations:\")\n",
    "recommendations = model.recommendProducts(userID, 10)\n",
    "for recommendation in recommendations:\n",
    "    print (\"\\t\" + nameDict[int(recommendation[1])] + \\\n",
    "        \" score \" + str(recommendation[2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results aren't really that great.\n",
    "- Very sensitive to the parameters chosen. Takes more work to find optimal parameters for a data set than to run the recommendations of parameters\n",
    "    - Can use \"train/test\" to evaluate various premutations of parameters\n",
    "    - But what is a \"good recommendation\" anyway?\n",
    "- I'm not convinced it's even working properly internally\n",
    "    - Putting your faith in a bblack box is dodgy\n",
    "    - We'd get better results using our movie similarity results instead, to find similar movies to movies each user liked.\n",
    "    - Complicated isn't always better.\n",
    "- Never blindly trust results when analyzing big data\n",
    "    - Smalll problems in algorithms become big ones\n",
    "    - Very often, quality of your input data is the real issue\n",
    "    \n",
    "### MLLib is still really useful!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
